{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a164089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F # FFFFF\n",
    "\n",
    "# Data loading\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Auxiliary functions\n",
    "from torch.utils.tensorboard import SummaryWriter  # Used for Tensorboard logging\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor, ceil\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701c2fd",
   "metadata": {},
   "source": [
    "# Segmentación de imagen mediante arquitectura U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feeee349",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ROOT = os.path.join('.')\n",
    "# Ruta para datos:\n",
    "PATH_DATA = os.path.join(PATH_ROOT, 'data')\n",
    "# Ruta para modelos:\n",
    "PATH_MODELS = os.path.join(PATH_ROOT, 'reports', 'models')\n",
    "# Ruta para resultados:\n",
    "PATH_RESULTS = os.path.join(PATH_ROOT, 'reports', 'results')\n",
    "# Ruta para ejecuciones:\n",
    "PATH_RUNS = os.path.join(PATH_ROOT, 'reports', 'runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f126c56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre del directorio de pruebas: 2025_11_12__21_25\n"
     ]
    }
   ],
   "source": [
    "# Para cada sesión creamos un directorio nuevo, a partir de la fecha y hora de su ejecución:\n",
    "date = datetime.datetime.now()\n",
    "test_name = str(date.year) + '_' + str(date.month) + '_' +  str(date.day) + '__' + str(date.hour) + '_' + str(date.minute)\n",
    "print('Nombre del directorio de pruebas: {}'.format(test_name))\n",
    "models_folder = os.path.join(PATH_MODELS, test_name)\n",
    "try:\n",
    "    os.makedirs(models_folder)\n",
    "except:\n",
    "    print(f'Folder {models_folder} already existed.')\n",
    "results_folder = os.path.join(PATH_RESULTS, test_name)\n",
    "try:\n",
    "    os.makedirs(results_folder)\n",
    "except:\n",
    "    print(f'Folder {results_folder} already existed.')\n",
    "runs_folder = os.path.join(PATH_RUNS, test_name)\n",
    "try:\n",
    "    os.makedirs(runs_folder)\n",
    "except:\n",
    "    print(f'Folder {runs_folder} already existed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06242d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2326a9",
   "metadata": {},
   "source": [
    "## Definición del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcb3d85",
   "metadata": {},
   "source": [
    "Como vamos a repetir la estructura de Convolución, Convolución, pooling, hacemos una clase para ello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a166a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dobleConvolucionMaxPool(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.convolucion_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)  \n",
    "        self.convolucion_2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True) #los índices indican posiciones de los máximos antes del pooling, para poder hacer el unpooling después.\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.convolucion_1(x))\n",
    "        x = torch.nn.functional.relu(self.convolucion_2(x))\n",
    "        skip_connection = x\n",
    "        x, indices = self.pool(x)\n",
    "        return x, indices, skip_connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c67df8",
   "metadata": {},
   "source": [
    "Lo mismo para hacer las deconvoluciones y el unpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dobleDeconvolucionMaxUnpool(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.convolucion_1 = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, padding=1)  \n",
    "        self.convolucion_2 = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.unpool = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, x, indices, skip_connection):\n",
    "        x = torch.nn.functional.relu(torch.cat([self.convolucion_1(x), skip_connection], dim=1))\n",
    "        x = torch.nn.functional.relu(self.convolucion_2(x))\n",
    "        x = self.unpool(x, indices, output_size=skip_connection.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e107bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_num_filtros(num_base_filtros, num_niveles):\n",
    "    filtros = []\n",
    "    for i in range(num_niveles):\n",
    "        filtros.append(num_base_filtros * (2**i)) # porque en cada nivel quermos duplicar el num de filtros\n",
    "    return filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14695004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_sizes=[10, 10], bias=True):\n",
    "        super().__init__()\n",
    "        self.capa_1 = nn.Linear(in_dim, hidden_sizes[0], bias=bias, device=device)\n",
    "        self.capa_2 = nn.Linear(hidden_sizes[0], hidden_sizes[1], bias=bias, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.capa_1(x))\n",
    "        x = self.capa_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddadc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_base_filtros = 64, num_niveles = 5, num_clases = 10):\n",
    "        super().__init__()\n",
    "        self.encoders = nn.ModuleList()\n",
    "        self.decoders = nn.ModuleList()\n",
    "        self.filtros = calcular_num_filtros(num_base_filtros, num_niveles)  # [64, 128, 256, 512, 1024] por defecto. Podemos aumentar el número de niveles para comprobar rendimiento\n",
    "        for i in range(num_niveles):\n",
    "            self.encoders.append(dobleConvolucionMaxPool(in_channels=self.filtros[i], out_channels=self.filtros[i+1]))\n",
    "            self.decoders.append(dobleDeconvolucionMaxUnpool(in_channels=self.filtros[num_niveles-i], out_channels=self.filtros[num_niveles-1-i])) # Queremos ir al revés\n",
    "        self.cuello_botella = MLP(self.filtros[-1], [4096, 4096])\n",
    "        self.convolucion_final = nn.Conv2d(self.filtros[0], num_clases, kernel_size=1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        indices = []\n",
    "        skip_connections = []\n",
    "        for encoder in self.encoders:\n",
    "            X, indice, skip_connection = encoder(X)\n",
    "            indices.append(indice)\n",
    "            skip_connections.append(skip_connection)\n",
    "        X_shape = X.shape\n",
    "        X = X.flatten(1)\n",
    "        X = self.cuello_botella(X)\n",
    "        X = X.reshape(X_shape)\n",
    "        for i, decoder in enumerate(self.decoders):\n",
    "            X = decoder(X, indices[len(indices)-1-i], skip_connections[len(skip_connections)-1-i].shape)\n",
    "        X = self.convolucion_final(X)\n",
    "        return X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
